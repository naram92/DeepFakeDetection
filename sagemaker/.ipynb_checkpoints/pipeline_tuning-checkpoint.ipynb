{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U sagemaker --quiet # Ensure latest version of SageMaker is installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepfake Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sagemaker\n",
    "import sagemaker.session\n",
    "from sagemaker.processing import FrameworkProcessor\n",
    "from sagemaker.sklearn import SKLearn\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import (\n",
    "    ProcessingStep, \n",
    "    CacheConfig,\n",
    "    TrainingStep,\n",
    "    TuningStep \n",
    ")\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.step_collections import RegisterModel, CreateModelStep\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.pytorch import PyTorch, PyTorchModel\n",
    "\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session = sagemaker.session.Session()\n",
    "region = session.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = session.default_bucket()\n",
    "pipeline_session = PipelineSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket_name = \"deepfake-detection\"\n",
    "output_prefix = \"datasets/preprocessed_data\"\n",
    "model_package_group_name = \"deepfake-detection\"  # Model name in model registry\n",
    "prefix = \"sagemaker/recsys-caser\"  # Prefix to S3 artifacts\n",
    "pipeline_name = \"deepfakePreprocessPipeline\"  # SageMaker Pipeline name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='parameters'></a>\n",
    "\n",
    "### Pipeline input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# What instance type to use for training\n",
    "training_instance_type = ParameterString(name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\")\n",
    "\n",
    "# What is the default status of the model when registering with model registry.\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\", default_value=\"PendingManualApproval\"\n",
    ")\n",
    "\n",
    "# # Cache Pipeline steps to reduce execution time on subsequent executions\n",
    "# cache_config = CacheConfig(enable_caching=True, expire_after=\"30d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='preprocess'></a>\n",
    "\n",
    "## Preprocess data step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create FrameworkProcessor\n",
    "sklearn_processor = FrameworkProcessor(\n",
    "    estimator_cls=PyTorch,\n",
    "    framework_version='1.12.0',\n",
    "    py_version='py38',\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    instance_count=1, # multiple machine distributed computing\n",
    "    base_job_name='deepfake-processing',\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frames_per_video = 15\n",
    "batch_size = 32\n",
    "face_size = 224\n",
    "thread_num = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sagemaker/workflow/pipeline_context.py:258: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "timestamp_prefix = str(int(time.time()))\n",
    "\n",
    "step_args = sklearn_processor.run(\n",
    "        code=\"preprocess_deepfake.py\",\n",
    "        source_dir='preprocess',\n",
    "        outputs=[\n",
    "            ProcessingOutput(\n",
    "                output_name=\"train\", \n",
    "                source=\"/opt/ml/processing/output/train\",\n",
    "                destination=Join(\n",
    "                    on=\"/\",\n",
    "                    values=[\n",
    "                        \"s3://{}\".format(bucket_name),\n",
    "                        output_prefix,\n",
    "                        timestamp_prefix,\n",
    "                        \"train\",\n",
    "                    ],\n",
    "                ),\n",
    "            ),\n",
    "            ProcessingOutput(\n",
    "                output_name=\"validation\", \n",
    "                source=\"/opt/ml/processing/output/validation\",\n",
    "                destination=Join(\n",
    "                    on=\"/\",\n",
    "                    values=[\n",
    "                        \"s3://{}\".format(bucket_name),\n",
    "                        output_prefix,\n",
    "                        timestamp_prefix,\n",
    "                        \"validation\",\n",
    "                    ],\n",
    "                ),\n",
    "            ),\n",
    "            ProcessingOutput(\n",
    "                output_name=\"test\", \n",
    "                source=\"/opt/ml/processing/output/test\",\n",
    "                destination=Join(\n",
    "                    on=\"/\",\n",
    "                    values=[\n",
    "                        \"s3://{}\".format(bucket_name),\n",
    "                        output_prefix,\n",
    "                        timestamp_prefix,\n",
    "                        \"test\",\n",
    "                    ],\n",
    "                ),\n",
    "            ),\n",
    "        ],\n",
    "        arguments=['--frames_per_video', str(frames_per_video),\n",
    "                   '--batch_size', str(batch_size),\n",
    "                   '--face_size', str(face_size),\n",
    "                   '--thread_num', str(thread_num)\n",
    "                  ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "step_preprocess_data = ProcessingStep(\n",
    "    name=\"preprocess-deepfake-data\",\n",
    "    step_args=step_args\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='tuning'></a>\n",
    "\n",
    "## Hyperparameter tuning \n",
    "Amazon SageMaker automatic model tuning, also known as hyperparameter tuning, finds the best version of a model by running many training jobs on your dataset using the algorithm and ranges of hyperparameters that you specify. It then chooses the hyperparameter values that result in a model that performs the best, as measured by a metric that you choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output path for the model artifacts from the Hyperparameter Tuning / Training Job\n",
    "model_path = f\"s3://{bucket}/deepfake/training\"\n",
    "\n",
    "est = PyTorch(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"./code\",  # directory of your training script\n",
    "    role=role,\n",
    "    framework_version=\"1.12.1\",\n",
    "    py_version=\"py38\",\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    output_path=model_path,\n",
    "    hyperparameters={\"batch-size\": 32, \n",
    "                     \"epochs\": 1, \n",
    "                     \"learning-rate\": 1e-4, \n",
    "                     \"num_workers\": 2\n",
    "                    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"batch-size\": CategoricalParameter([32, 64]),\n",
    "# \"learning-rate\": ContinuousParameter(0.01, 0.1)\n",
    "hyperparameter_ranges = {\n",
    "    \"batch-size\": CategoricalParameter([32, 64])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = \"accuracy\"\n",
    "objective_type = \"Maximize\"\n",
    "metric_definitions = [{\"Name\": \"accuracy\", \"Regex\": \"'ndcg@5': ([0-9\\\\.]+)\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stopping_type (str) â€“ Specifies whether early stopping is enabled for the job. \n",
    "# Stop the training jobs that a hyperparameter tuning job launches early when they are not improving significantly as measured by the objective metric. \n",
    "# Stopping training jobs early can help reduce compute time and helps you avoid overfitting your model. \n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    est,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    max_jobs=2,\n",
    "    max_parallel_jobs=2,\n",
    "    objective_type=objective_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add cache config if necessary\n",
    "# cache_config=cache_config\n",
    "step_tuning = TuningStep(\n",
    "    name=\"deepfake-HPTuning\",\n",
    "    tuner=tuner,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_preprocess_data.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\"\n",
    "            ].S3Output.S3Uri\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_preprocess_data.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='evaluate'></a>\n",
    "\n",
    "## Evaluate top model\n",
    "After successfully completing the Hyperparameter Tuning job. You can either create SageMaker models from the model artifacts created by the training jobs from the TuningStep or register the models into the Model Registry.\n",
    "\n",
    "When using the model Registry, if you register multiple models from the TuningStep, they will be registered as versions within the same model package group unless unique model package groups are specified for each RegisterModelStep that is part of the pipeline.\n",
    "\n",
    "In this notebook, the two best models from the TuningStep are added to the same model package group in the Model Registry as v0 and v1.\n",
    "\n",
    "You use the get_top_model_s3_uri method of the TuningStep class to get the model artifact from one of the top performing model versions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A ProcessingStep is used to evaluate the performance of a selected model from the HPO step. In this case, the top performing model\n",
    "# is evaluated. Based on the results of the evaluation, the model is registered into the Model Registry using a ConditionStep.\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "model_bucket_key = f\"{bucket}/deepfake/training\"\n",
    "\n",
    "image_uri = retrieve(\n",
    "    framework='pytorch', \n",
    "    region='us-east-1', \n",
    "    version='1.12.1', \n",
    "    py_version='py38', \n",
    "    image_scope='training',\n",
    "    instance_type='ml.m5.xlarge'\n",
    ")\n",
    "\n",
    "evaluate_model_processor = ScriptProcessor(\n",
    "    role=get_execution_role(),\n",
    "    image_uri=image_uri,\n",
    "    command=['python3'],\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge'\n",
    ")\n",
    "\n",
    "# Create a PropertyFile\n",
    "# A PropertyFile is used to be able to reference outputs from a processing step, for instance to use in a condition step.\n",
    "# For more information, visit https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-propertyfile.html\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"BestTuningModelEvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "# This can be extended to evaluate multiple models from the HPO step\n",
    "# cache_config=cache_config\n",
    "step_evaluate_model = ProcessingStep(\n",
    "    name=\"Evaluate-Top-Deepfake-Detection-Model\",\n",
    "    processor=evaluate_model_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_tuning.get_top_model_s3_uri(top_k=0, s3_bucket=model_bucket_key),\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_preprocess_data.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/train\",\n",
    "        ),\n",
    "         ProcessingInput(\n",
    "            source=step_preprocess_data.properties.ProcessingOutputConfig.Outputs[\"validation\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/validation\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_preprocess_data.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"evaluation\", \n",
    "            source=\"/opt/ml/processing/evaluation\",\n",
    "            destination = Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3://{}\".format(bucket),\n",
    "                    \"deepfake/output\",\n",
    "                    timestamp_prefix,\n",
    "                    \"evaluation-report\",\n",
    "                ],\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    code=\"evaluate/evaluate.py\",\n",
    "    property_files=[evaluation_report]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='register'></a>\n",
    "\n",
    "## Register model step\n",
    "If the trained model meets the model performance requirements a new model version is registered with the model registry for further analysis. To attach model metrics to the model version, create a [ModelMetrics](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-metrics.html) object using the evaluation report created in the evaluation step. Then, create the RegisterModel step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "# Create ModelMetrics object using the evaluation report from the evaluation step\n",
    "# A ModelMetrics object contains metrics captured from a model.\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=Join(\n",
    "            on=\"/\",\n",
    "            values=[\n",
    "                step_evaluate_model.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\n",
    "                    \"S3Uri\"\n",
    "                ],\n",
    "                \"evaluation.json\",\n",
    "            ],\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Crete a RegisterModel step, which registers the model with Sagemaker Model Registry.\n",
    "step_register_model = RegisterModel(\n",
    "    name=\"Register-Best-Deepfake-Detection-Model\",\n",
    "    estimator=est,\n",
    "    model_data=step_tuning.get_top_model_s3_uri(top_k=0, s3_bucket=model_bucket_key),\n",
    "    content_types=[\"text/csv\"], # \n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.m5.xlarge\", \"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='condition'></a>\n",
    "\n",
    "## Condition step\n",
    "Adding conditions to the pipeline is done with a ConditionStep.\n",
    "In this case, we only want to register the new model version with the model registry if the new model meets a ndcg condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "# Create accuracy condition to ensure the model meets performance requirements.\n",
    "# Models with a test accuracy lower than the condition will not be registered with the model registry.\n",
    "cond_gte = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=step_evaluate_model.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"deepfake_metrics.accuracy.value\",\n",
    "    ),\n",
    "    right=70.0, #minimum accuracy value\n",
    ")\n",
    "\n",
    "# Create a Sagemaker Pipelines ConditionStep, using the condition above.\n",
    "# Enter the steps to perform if the condition returns True / False.\n",
    "step_cond = ConditionStep(\n",
    "    name=\"Accuracy-Condition\",\n",
    "    conditions=[cond_gte],\n",
    "    if_steps=[step_register_model],\n",
    "    else_steps=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='orchestrate'></a>\n",
    "\n",
    "## Pipeline Creation: Orchestrate all steps\n",
    "\n",
    "Now that all pipeline steps are created, a pipeline is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "# Create a Sagemaker Pipeline.\n",
    "# Each parameter for the pipeline must be set as a parameter explicitly when the pipeline is created.\n",
    "# Also pass in each of the steps created above.\n",
    "# Note that the order of execution is determined from each step's dependencies on other steps,\n",
    "# not on the order they are passed in below.\n",
    "# pipeline = Pipeline(\n",
    "#     name=pipeline_name,\n",
    "#     parameters=[\n",
    "#         processing_instance_type,\n",
    "#         processing_instance_count,\n",
    "#         training_instance_type,\n",
    "#         model_approval_status,\n",
    "#         input_data,\n",
    "#     ],\n",
    "#     steps=[step_preprocess_data, step_tuning, step_evaluate_model, step_cond],\n",
    "# )\n",
    "\n",
    "# Run only preprocess step\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    steps=[step_preprocess_data],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# definition = json.loads(pipeline.definition())\n",
    "# definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:Uploaded preprocess to s3://sagemaker-us-east-1-674518009863/deepfakePreprocessPipeline/code/0e9c5054e4ca1579c7d639a579213703/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sagemaker-us-east-1-674518009863/deepfakePreprocessPipeline/code/aba9cd410894d4dc1aa101779eb7c8dd/runproc.sh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  deepfake-processing-2023-01-03-02-09-30-621\n",
      "Inputs:  [{'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-674518009863/deepfakePreprocessPipeline/code/0e9c5054e4ca1579c7d639a579213703/sourcedir.tar.gz', 'LocalPath': '/opt/ml/processing/input/code/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'entrypoint', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-674518009863/deepfakePreprocessPipeline/code/aba9cd410894d4dc1aa101779eb7c8dd/runproc.sh', 'LocalPath': '/opt/ml/processing/input/entrypoint', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'train', 'AppManaged': False, 'S3Output': {'S3Uri': Join(on='/', values=['s3://deepfake-detection', 'datasets/preprocessed_data', '1672711763', 'train']), 'LocalPath': '/opt/ml/processing/output/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'validation', 'AppManaged': False, 'S3Output': {'S3Uri': Join(on='/', values=['s3://deepfake-detection', 'datasets/preprocessed_data', '1672711763', 'validation']), 'LocalPath': '/opt/ml/processing/output/validation', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'test', 'AppManaged': False, 'S3Output': {'S3Uri': Join(on='/', values=['s3://deepfake-detection', 'datasets/preprocessed_data', '1672711763', 'test']), 'LocalPath': '/opt/ml/processing/output/test', 'S3UploadMode': 'EndOfJob'}}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'StepName': 'preprocess-deepfake-data',\n",
       "  'StartTime': datetime.datetime(2023, 1, 3, 2, 9, 32, 76000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2023, 1, 3, 2, 13, 52, 87000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:674518009863:processing-job/pipelines-q31zw6sef1qb-preprocess-deepfake--fxpibdlr5p'}}}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Submit pipline\n",
    "pipeline.upsert(role_arn=role)\n",
    "\n",
    "# Execute pipeline using the default parameters.\n",
    "execution = pipeline.start()\n",
    "\n",
    "execution.wait()\n",
    "\n",
    "# List the execution steps to check out the status and artifacts:\n",
    "execution.list_steps()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (Base Python 2.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-base-python-38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
